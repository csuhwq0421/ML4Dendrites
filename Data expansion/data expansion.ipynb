{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input bayesian dataset\n",
    "data = pd.read_excel('data_new.xlsx', sheet_name='bayes-01')\n",
    "feature_cols = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Simply observe the distribution of the Bayesian data set\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))  \n",
    "fig.suptitle('Feature Distributions', fontsize=16)  \n",
    "\n",
    "for i, feature in enumerate(feature_cols):\n",
    "    row = i // 3  \n",
    "    col = i % 3   \n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    sns.histplot(data[feature], kde=True, ax=ax, color='skyblue', bins=20)\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "if len(feature_cols) < 6:\n",
    "    for j in range(len(feature_cols), 6):\n",
    "        row = j // 3\n",
    "        col = j % 3\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data point with the largest MAE was determined by k-fold k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "\n",
    "class FileManager:\n",
    "    def __init__(self, base_file='Initial_data.xlsx'):\n",
    "        self.base_file = base_file\n",
    "\n",
    "    def load_data(self, sheet_name):\n",
    "        \"\"\"Load data\"\"\"\n",
    "        try:\n",
    "            data = pd.read_excel(self.base_file, sheet_name=sheet_name)\n",
    "            print(f\"Successfully loaded data from worksheet '{sheet_name}'\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load worksheet '{sheet_name}': {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @staticmethod\n",
    "    def save_to_new_excel(data, file_name='Sorted_data.xlsx', sheet_name='Sorted_data', index=False):\n",
    "        \"\"\"Save data\"\"\"\n",
    "        try:\n",
    "            with pd.ExcelWriter(file_name, mode='w', engine='openpyxl') as writer:\n",
    "                data.to_excel(writer, sheet_name=sheet_name, index=index)\n",
    "            print(f\"Successfully saved data to file '{file_name}', sheet '{sheet_name}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save data to file '{file_name}': {e}\")\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data):\n",
    "    \"\"\"Preprocess input data\"\"\"\n",
    "    continuous_cols = ['x1', 'x2', 'x3', 'x4']\n",
    "    categorical_cols = ['x5']\n",
    "    target_col = 'y1'\n",
    "\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    # encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "    # X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "    # X_encoded = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    # X = pd.concat([X.drop(categorical_cols, axis=1), X_encoded], axis=1)\n",
    "\n",
    "    return X, y, data\n",
    "\n",
    "\n",
    "def evaluate_model_and_store_predictions(X, y, model, num_repeats, num_folds):\n",
    "    \"\"\"Evaluate model performance using repeated K-Fold cross-validation\"\"\"\n",
    "    all_r2_scores = []\n",
    "    all_mae_scores = []\n",
    "    all_rmse_scores = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for j in range(num_repeats):\n",
    "        cv = KFold(n_splits=num_folds, shuffle=True, random_state=j)\n",
    "        fold_predictions = []\n",
    "\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            r2_fold = r2_score(y_test, y_test_pred)\n",
    "            mae_fold = mean_absolute_error(y_test, y_test_pred)\n",
    "            rmse_fold = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            all_r2_scores.append(r2_fold)\n",
    "            all_mae_scores.append(mae_fold)\n",
    "            all_rmse_scores.append(rmse_fold)\n",
    "            fold_predictions.append(pd.Series(y_test_pred, index=test_index))\n",
    "\n",
    "        combined_fold_predictions = pd.concat(fold_predictions).sort_index()\n",
    "        all_predictions.append(combined_fold_predictions)\n",
    "\n",
    "    all_predictions_df = pd.concat(all_predictions, axis=1)\n",
    "    mean_predictions = all_predictions_df.mean(axis=1)\n",
    "    std_predictions = all_predictions_df.std(axis=1)\n",
    "\n",
    "    return mean_predictions, std_predictions, all_predictions_df, all_r2_scores, all_mae_scores, all_rmse_scores\n",
    "\n",
    "\n",
    "def normalize_features(df, feature_ranges):\n",
    "    \"\"\"Normalize features\"\"\"\n",
    "    normalized_df = df.copy()\n",
    "    for col, (min_val, max_val) in feature_ranges.items():\n",
    "        normalized_df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return normalized_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    file_manager = FileManager(base_file='Initial_data.xlsx')\n",
    "    initial_data = file_manager.load_data(sheet_name='bayes-01')\n",
    "\n",
    "    if initial_data.empty:\n",
    "        print(\"Failed to load initial data. Please check the file content.\")\n",
    "        exit(1)\n",
    "\n",
    "    X, y, data = load_and_preprocess_data(initial_data)\n",
    "\n",
    "    xgb = XGBRegressor(max_depth=5, learning_rate=0.10, n_estimators=125,\n",
    "                       reg_lambda=10, reg_alpha=0, min_child_weight=3,\n",
    "                       subsample=1.0, colsample_bytree=0.6)\n",
    "\n",
    "    mean_predictions, std_predictions, all_predictions_df, all_r2_scores, all_mae_scores, all_rmse_scores = \\\n",
    "        evaluate_model_and_store_predictions(\n",
    "            X, y, xgb, num_repeats=5, num_folds=5\n",
    "        )\n",
    "\n",
    "    r2_mean = np.mean(all_r2_scores)\n",
    "    r2_std = np.std(all_r2_scores)\n",
    "    mae_mean = np.mean(all_mae_scores)\n",
    "    mae_std = np.std(all_mae_scores)\n",
    "    rmse_mean = np.mean(all_rmse_scores)\n",
    "    rmse_std = np.std(all_rmse_scores)\n",
    "\n",
    "    print(\"\\n=== Repeated Cross-Validation Results ===\")\n",
    "    print(f\"RÂ² Mean: {r2_mean:.4f}, Std: {r2_std:.4f}\")\n",
    "    print(f\"MAE Mean: {mae_mean:.4f}, Std: {mae_std:.4f}\")\n",
    "    print(f\"RMSE Mean: {rmse_mean:.4f}, Std: {rmse_std:.4f}\")\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Actual': y,\n",
    "        'Mean_Prediction': mean_predictions,\n",
    "        'Std_Prediction': std_predictions\n",
    "    })\n",
    "    results = pd.concat([X, results], axis=1)\n",
    "    results['Absolute_Error'] = np.abs(results['Actual'] - results['Mean_Prediction'])\n",
    "    results_sorted = results.sort_values(by='Absolute_Error', ascending=False)\n",
    "\n",
    "    FileManager.save_to_new_excel(results_sorted, file_name='Sorted_data_col=0.6-r3.xlsx', sheet_name='Sorted_data', index=True)\n",
    "\n",
    "    # Option to normalize features\n",
    "    need_normalize = False  # Set to True if normalization is needed\n",
    "    if need_normalize:\n",
    "        feature_ranges = {\n",
    "            'x1': (580, 680),\n",
    "            'x2': (220, 300),\n",
    "            'x3': (0.025, 0.15),\n",
    "            'x4': (0.01, 0.04)\n",
    "        }\n",
    "        X_normalized = normalize_features(X, feature_ranges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
