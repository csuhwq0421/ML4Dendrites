{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b96968b",
   "metadata": {},
   "source": [
    "## Load and preproceess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom normalization function\n",
    "def custom_normalize(df, feature_ranges):\n",
    "    \"\"\"\n",
    "    Normalize specified columns according to given [min, max] ranges.\n",
    "    \n",
    "    :param df: Original DataFrame\n",
    "    :param feature_ranges: Dictionary format, e.g. {'x1': (580, 680), 'x2': (220, 300)}\n",
    "    :return: Normalized DataFrame\n",
    "    \"\"\"\n",
    "    normalized_df = df.copy()\n",
    "    for col, (min_val, max_val) in feature_ranges.items():\n",
    "        normalized_df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return normalized_df\n",
    "\n",
    "# Load data from Excel file\n",
    "data = pd.read_excel('Initial_data.xlsx', sheet_name='bayes-01')\n",
    "\n",
    "# Define input features and target column\n",
    "features = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "target_col = 'y1'\n",
    "\n",
    "# Split features and target variable\n",
    "X = data[features]\n",
    "y = data[target_col]\n",
    "\n",
    "# Apply custom normalization based on specified ranges\n",
    "feature_ranges = {\n",
    "    'x1': (580, 680),\n",
    "    'x2': (220, 300),\n",
    "    'x3': (0.025, 0.15),\n",
    "    'x4': (0.01, 0.04),\n",
    "    'x5': (0.0, 1.0)  # Example: assuming x5 range is [0, 1]\n",
    "}\n",
    "\n",
    "X = custom_normalize(X, feature_ranges)\n",
    "\n",
    "# Define feature names for later use (e.g., model interpretation or visualization)\n",
    "feature_names = ['x1', 'x2', 'x3', 'x4', 'x5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to train and evaluate the model using repeated cross-validation\n",
    "def train_evaluate_model(model, model_name, X, y, num_repeats=5, num_folds=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model using repeated K-Fold cross-validation.\n",
    "    \n",
    "    :param model: Model object (e.g., from scikit-learn)\n",
    "    :param model_name: Name of the model (string)\n",
    "    :param X: Feature data\n",
    "    :param y: Target variable\n",
    "    :param num_repeats: Number of repetitions for cross-validation\n",
    "    :param num_folds: Number of folds per repetition\n",
    "    :return: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    all_r2_train = []\n",
    "    all_rmse_train = []\n",
    "    all_mae_train = []\n",
    "    all_r2_test = []\n",
    "    all_rmse_test = []\n",
    "    all_mae_test = []\n",
    "\n",
    "    all_y_train = []\n",
    "    all_y_train_pred = []\n",
    "    all_y_test = []\n",
    "    all_y_test_pred = []\n",
    "    all_x_train = []\n",
    "    all_x_test = []\n",
    "\n",
    "    # Perform repeated cross-validation\n",
    "    for i in range(num_repeats):\n",
    "        cv = KFold(n_splits=num_folds, shuffle=True, random_state=i)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            # Store results\n",
    "            all_y_train.append(y_train)\n",
    "            all_y_train_pred.append(y_train_pred)\n",
    "            all_y_test.append(y_test)\n",
    "            all_y_test_pred.append(y_test_pred)\n",
    "            all_x_train.append(X_train)\n",
    "            all_x_test.append(X_test)\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            all_r2_train.append(r2_score(y_train, y_train_pred))\n",
    "            all_rmse_train.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "            all_mae_train.append(mean_absolute_error(y_train, y_train_pred))\n",
    "\n",
    "            all_r2_test.append(r2_score(y_test, y_test_pred))\n",
    "            all_rmse_test.append(np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "            all_mae_test.append(mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "    # Concatenate all true and predicted values\n",
    "    y_train_combined = np.concatenate(all_y_train)\n",
    "    y_train_pred_combined = np.concatenate(all_y_train_pred)\n",
    "    y_test_combined = np.concatenate(all_y_test)\n",
    "    y_test_pred_combined = np.concatenate(all_y_test_pred)\n",
    "\n",
    "    x_train_combined = np.concatenate(all_x_train)\n",
    "    x_test_combined = np.concatenate(all_x_test)\n",
    "\n",
    "    # Compute mean and standard deviation of metrics\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_r2_mean': np.mean(all_r2_train),\n",
    "        'train_r2_std': np.std(all_r2_train),\n",
    "        'train_rmse_mean': np.mean(all_rmse_train),\n",
    "        'train_rmse_std': np.std(all_rmse_train),\n",
    "        'train_mae_mean': np.mean(all_mae_train),\n",
    "        'train_mae_std': np.std(all_mae_train),\n",
    "\n",
    "        'test_r2_mean': np.mean(all_r2_test),\n",
    "        'test_r2_std': np.std(all_r2_test),\n",
    "        'test_rmse_mean': np.mean(all_rmse_test),\n",
    "        'test_rmse_std': np.std(all_rmse_test),\n",
    "        'test_mae_mean': np.mean(all_mae_test),\n",
    "        'test_mae_std': np.std(all_mae_test),\n",
    "    }\n",
    "\n",
    "    # Print performance summary\n",
    "    print(f\"\\n=== {model_name} Performance ===\")\n",
    "    print(f\"Train R² Mean: {metrics['train_r2_mean']:.4f}, Std: {metrics['train_r2_std']:.4f}\")\n",
    "    print(f\"Train RMSE Mean: {metrics['train_rmse_mean']:.4f}, Std: {metrics['train_rmse_std']:.4f}\")\n",
    "    print(f\"Train MAE Mean: {metrics['train_mae_mean']:.4f}, Std: {metrics['train_mae_std']:.4f}\")\n",
    "    print(f\"Test R² Mean: {metrics['test_r2_mean']:.4f}, Std: {metrics['test_r2_std']:.4f}\")\n",
    "    print(f\"Test RMSE Mean: {metrics['test_rmse_mean']:.4f}, Std: {metrics['test_rmse_std']:.4f}\")\n",
    "    print(f\"Test MAE Mean: {metrics['test_mae_mean']:.4f}, Std: {metrics['test_mae_std']:.4f}\")\n",
    "\n",
    "    # Plot true vs predicted values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_train_combined, y_train_pred_combined, color='blue', label='Training Set', alpha=0.6)\n",
    "    plt.scatter(y_test_combined, y_test_pred_combined, color='red', label='Test Set', alpha=0.6)\n",
    "    plt.plot([y_train_combined.min(), y_train_combined.max()],\n",
    "             [y_train_combined.min(), y_train_combined.max()],\n",
    "             color='green', linestyle='--', label='Ideal Line')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'True vs Predicted ({model_name})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Save prediction results into DataFrames\n",
    "    train_data = pd.DataFrame({\n",
    "        'Conditions': [','.join(map(str, row)) for row in x_train_combined],\n",
    "        'True_Y': y_train_combined,\n",
    "        'Predicted_Y': y_train_pred_combined\n",
    "    })\n",
    "\n",
    "    test_data = pd.DataFrame({\n",
    "        'Conditions': [','.join(map(str, row)) for row in x_test_combined],\n",
    "        'True_Y': y_test_combined,\n",
    "        'Predicted_Y': y_test_pred_combined\n",
    "    })\n",
    "\n",
    "    # Export to Excel with model name included in filename\n",
    "    train_data.to_excel(f'train_predictions_{model_name}.xlsx', index=False)\n",
    "    test_data.to_excel(f'test_predictions_{model_name}.xlsx', index=False)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6919de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# Define the machine learning model\n",
    "kernel = Matern(length_scale=1.0, nu=1.5) \n",
    "gpr = GaussianProcessRegressor(\n",
    "    kernel=kernel,                     \n",
    "    alpha=0.1,                        \n",
    "    n_restarts_optimizer=20,          \n",
    "    normalize_y=True                   \n",
    ")\n",
    "\n",
    "# Training and evaluation of the machine learning model\n",
    "gpr_metrics = train_evaluate_model(gpr, \"GPR\", X, y, num_repeats=5, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR  \n",
    "svr = SVR(kernel='rbf', C=1, epsilon=0.01,)\n",
    "SVR_metrics = train_evaluate_model(svr, \"SVR\", X, y, num_repeats=5, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(random_state=42, learning_rate_init = 0.01, learning_rate='adaptive',\n",
    "             hidden_layer_sizes=(200, 500), alpha=0.05, activation='relu', max_iter=1000)\n",
    "mlp_metrics = train_evaluate_model(mlp, \"mlp\", X, y, num_repeats=5, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=5, min_samples_leaf=2, min_samples_split=2)\n",
    "dt = train_evaluate_model(dt, \"dt\", X, y, num_repeats=5, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60788b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "extra_tree = ExtraTreesRegressor(n_estimators=100, max_depth=125, min_samples_split=3,min_samples_leaf=1,random_state=1)\n",
    "extra_tree = train_evaluate_model(model=extra_tree,model_name=\"extra_tree\",X=X,y=y,num_repeats=5,num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=125, reg_lambda=10, reg_alpha=0,\n",
    "                   min_child_weight=3, subsample=1, colsample_bytree=0.6)\n",
    "xgb = train_evaluate_model(xgb, \"xgb\", X, y, num_repeats=5, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load data from Excel file\n",
    "data = pd.read_excel('Total_data.xlsx')\n",
    "\n",
    "\n",
    "X = data.iloc[:, :5]   \n",
    "y = data.iloc[:, 5]    \n",
    "feature_names = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "xgb = XGBRegressor(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=240,\n",
    "    reg_lambda=5,\n",
    "    reg_alpha=0.01,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "# Define number of repeated cross-validation loops and folds\n",
    "num_repeats = 5\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "all_r2_train = []\n",
    "all_rmse_train = []\n",
    "all_mae_train = []\n",
    "all_r2_test = []\n",
    "all_rmse_test = []\n",
    "all_mae_test = []\n",
    "all_y_train = []\n",
    "all_y_train_pred = []\n",
    "all_y_test = []\n",
    "all_y_test_pred = []\n",
    "all_x_train = []\n",
    "all_x_test = []\n",
    "all_mae_test_y_lt_150 = []  \n",
    "\n",
    "model_rf_results = []\n",
    "\n",
    "# K-repeated K-Fold Cross Validator\n",
    "for i in range(num_repeats):\n",
    "\n",
    "    \n",
    "    cv = KFold(n_splits=num_folds, shuffle=True, random_state=i)\n",
    "\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        all_y_train.append(y_train)\n",
    "        all_y_train_pred.append(y_train_pred)\n",
    "        all_y_test.append(y_test)\n",
    "        all_y_test_pred.append(y_test_pred)\n",
    "        all_x_train.append(X_train)\n",
    "        all_x_test.append(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "        all_r2_train.append(r2_train)\n",
    "        all_rmse_train.append(rmse_train)\n",
    "        all_mae_train.append(mae_train)\n",
    "        all_r2_test.append(r2_test)\n",
    "        all_rmse_test.append(rmse_test)\n",
    "        all_mae_test.append(mae_test)\n",
    "        \n",
    "        y_test_lt_150 = y_test < 1.50\n",
    "        if np.any(y_test_lt_150):  \n",
    "            mae_test_y_lt_150 = mean_absolute_error(y_test[y_test_lt_150], y_test_pred[y_test_lt_150])\n",
    "            all_mae_test_y_lt_150.append(mae_test_y_lt_150)\n",
    "\n",
    "# Calculate mean and standard deviation of evaluation metrics\n",
    "mean_r2_train = np.mean(all_r2_train)\n",
    "std_r2_train = np.std(all_r2_train)\n",
    "mean_rmse_train = np.mean(all_rmse_train)\n",
    "std_rmse_train = np.std(all_rmse_train)\n",
    "mean_mae_train = np.mean(all_mae_train)\n",
    "std_mae_train = np.std(all_mae_train)\n",
    "\n",
    "mean_r2_test = np.mean(all_r2_test)\n",
    "std_r2_test = np.std(all_r2_test)\n",
    "mean_rmse_test = np.mean(all_rmse_test)\n",
    "std_rmse_test = np.std(all_rmse_test)\n",
    "mean_mae_test = np.mean(all_mae_test)\n",
    "std_mae_test = np.std(all_mae_test)\n",
    "\n",
    "\n",
    "mean_mae_test_y_lt_150 = np.mean(all_mae_test_y_lt_150)\n",
    "std_mae_test_y_lt_150 = np.std(all_mae_test_y_lt_150)\n",
    "\n",
    "print(\"\\nTraining Set - R2 Score\", mean_r2_train)\n",
    "print(\"Training Set - std R2 Score\", std_r2_train)\n",
    "print(\"Training Set - RMSE\", mean_rmse_train)\n",
    "print(\"Training Set - std RMSE Score\", std_rmse_train)\n",
    "print(\"Training Set - MAE\", mean_mae_train)\n",
    "print(\"Training Set - std MAE Score\", std_mae_train)\n",
    "print(\"Test Set - R2 Score\", mean_r2_test)\n",
    "print(\"Test Set - std R2 Score\", std_r2_test)\n",
    "print(\"Test Set - RMSE\", mean_rmse_test)\n",
    "print(\"Test Set - std RMSE Score\", std_rmse_test)\n",
    "print(\"Test Set - MAE\", mean_mae_test)\n",
    "print(\"Test Set - std MAE Score\", std_mae_test)\n",
    "print(\"Test Set - MAE (y < 1.50)\", mean_mae_test_y_lt_150)\n",
    "print(\"Test Set - std MAE (y < 1.50)\", std_mae_test_y_lt_150)\n",
    "\n",
    "\n",
    "# Plot predicted vs true values\n",
    "y_train_combined = np.concatenate(all_y_train)\n",
    "y_train_pred_combined = np.concatenate(all_y_train_pred)\n",
    "y_test_combined = np.concatenate(all_y_test)\n",
    "y_test_pred_combined = np.concatenate(all_y_test_pred)\n",
    "x_test_combined = np.concatenate(all_x_test)\n",
    "x_train_combined = np.concatenate(all_x_train)\n",
    "plt.scatter(y_train_combined, y_train_pred_combined, color='blue', label='Training Set')\n",
    "plt.scatter(y_test_combined, y_test_pred_combined, color='red', label='Test Set')\n",
    "plt.plot([min(y_train_combined), max(y_train_combined)], [min(y_train_combined), max(y_train_combined)], color='green', label='Ideal')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save prediction results into DataFrames\n",
    "train_data = pd.DataFrame({\n",
    "        'Conditions': [','.join(map(str, row)) for row in x_train_combined],\n",
    "        'True_Y': y_train_combined,\n",
    "        'Predicted_Y': y_train_pred_combined\n",
    "    })\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "        'Conditions': [','.join(map(str, row)) for row in x_test_combined],\n",
    "        'True_Y': y_test_combined,\n",
    "        'Predicted_Y': y_test_pred_combined\n",
    "    })\n",
    "\n",
    "    # Export to Excel with model name included in filename\n",
    "train_data.to_excel(f'train_predictions_xgb_all_data_col=0.5.xlsx', index=False)\n",
    "test_data.to_excel(f'test_predictions_xgb_all_data_col=0.5.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
