{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the XGBOOST model through SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data from Excel file\n",
    "data = pd.read_excel('Total_data.xlsx')\n",
    "\n",
    "\n",
    "X = data.iloc[:, :5]   \n",
    "y = data.iloc[:, 5]    \n",
    "feature_names = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "xgb = XGBRegressor(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.10,\n",
    "    n_estimators=220,\n",
    "    reg_lambda=5,\n",
    "    reg_alpha=0.01,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "# Define number of repeated cross-validation loops and folds\n",
    "num_repeats = 5\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "all_r2_train = []\n",
    "all_rmse_train = []\n",
    "all_mae_train = []\n",
    "all_r2_test = []\n",
    "all_rmse_test = []\n",
    "all_mae_test = []\n",
    "all_y_train = []\n",
    "all_y_train_pred = []\n",
    "all_y_test = []\n",
    "all_y_test_pred = []\n",
    "all_x_train = []\n",
    "all_x_test = []\n",
    "\n",
    "model_rf_results = []\n",
    "\n",
    "# K-repeated K-Fold Cross Validator\n",
    "for i in range(num_repeats):\n",
    "\n",
    "    \n",
    "    cv = KFold(n_splits=num_folds, shuffle=True, random_state=i)\n",
    "\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        all_y_train.append(y_train)\n",
    "        all_y_train_pred.append(y_train_pred)\n",
    "        all_y_test.append(y_test)\n",
    "        all_y_test_pred.append(y_test_pred)\n",
    "        all_x_train.append(X_train)\n",
    "        all_x_test.append(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "        all_r2_train.append(r2_train)\n",
    "        all_rmse_train.append(rmse_train)\n",
    "        all_mae_train.append(mae_train)\n",
    "        all_r2_test.append(r2_test)\n",
    "        all_rmse_test.append(rmse_test)\n",
    "        all_mae_test.append(mae_test)\n",
    "\n",
    "# Calculate mean and standard deviation of evaluation metrics\n",
    "mean_r2_train = np.mean(all_r2_train)\n",
    "std_r2_train = np.std(all_r2_train)\n",
    "mean_rmse_train = np.mean(all_rmse_train)\n",
    "std_rmse_train = np.std(all_rmse_train)\n",
    "mean_mae_train = np.mean(all_mae_train)\n",
    "std_mae_train = np.std(all_mae_train)\n",
    "\n",
    "mean_r2_test = np.mean(all_r2_test)\n",
    "std_r2_test = np.std(all_r2_test)\n",
    "mean_rmse_test = np.mean(all_rmse_test)\n",
    "std_rmse_test = np.std(all_rmse_test)\n",
    "mean_mae_test = np.mean(all_mae_test)\n",
    "std_mae_test = np.std(all_mae_test)\n",
    "\n",
    "print(\"\\nTraining Set - R2 Score\", mean_r2_train)\n",
    "print(\"Training Set - std R2 Score\", std_r2_train)\n",
    "print(\"Training Set - RMSE\", mean_rmse_train)\n",
    "print(\"Training Set - std RMSE Score\", std_rmse_train)\n",
    "print(\"Training Set - MAE\", mean_mae_train)\n",
    "print(\"Training Set - std MAE Score\", std_mae_train)\n",
    "print(\"Test Set - R2 Score\", mean_r2_test)\n",
    "print(\"Test Set - std R2 Score\", std_r2_test)\n",
    "print(\"Test Set - RMSE\", mean_rmse_test)\n",
    "print(\"Test Set - std RMSE Score\", std_rmse_test)\n",
    "print(\"Test Set - MAE\", mean_mae_test)\n",
    "print(\"Test Set - std MAE Score\", std_mae_test)\n",
    "\n",
    "\n",
    "# Plot predicted vs true values\n",
    "y_train_combined = np.concatenate(all_y_train)\n",
    "y_train_pred_combined = np.concatenate(all_y_train_pred)\n",
    "y_test_combined = np.concatenate(all_y_test)\n",
    "y_test_pred_combined = np.concatenate(all_y_test_pred)\n",
    "x_test_combined = np.concatenate(all_x_test)\n",
    "x_train_combined = np.concatenate(all_x_train)\n",
    "plt.scatter(y_train_combined, y_train_pred_combined, color='blue', label='Training Set')\n",
    "plt.scatter(y_test_combined, y_test_pred_combined, color='red', label='Test Set')\n",
    "plt.plot([min(y_train_combined), max(y_train_combined)], [min(y_train_combined), max(y_train_combined)], color='green', label='Ideal')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb = XGBRegressor(max_depth=5, learning_rate=0.10, n_estimators=240, reg_lambda=5, reg_alpha=0.01,\n",
    "min_child_weight=3, subsample=0.8, colsample_bytree=0.5)\n",
    "model=xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Initialize JavaScript visualization for SHAP in Jupyter Notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create a model explainer using TreeExplainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values for the entire dataset\n",
    "shap_values = explainer.shap_values(X)\n",
    "expected_value = np.array([explainer.expected_value])\n",
    "\n",
    "# Convert shap_values into a SHAP Explanation object (optional, for advanced usage)\n",
    "shap_exp = shap.Explanation(values=shap_values, data=X)\n",
    "\n",
    "# Generate and display a summary plot of feature importances using bar chart\n",
    "shap.summary_plot(shap_values, X, feature_names=feature_names, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "src_names = ['$T_{Re}$', '$T_{se}$', '$c_{Re}$', '$f_{H_2}$','Sub.']\n",
    "# 生成Beeswarm图\n",
    "shap.summary_plot(shap_values, X, feature_names=src_names, plot_size=(8, 6.2), show=False)\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = fig.axes[0]\n",
    "\n",
    "for child in ax.get_children():\n",
    "    if isinstance(child, Line2D):\n",
    "        \n",
    "        child.set_linewidth(1.5)      \n",
    "        # child.set_linestyle('-')  \n",
    "        child.set_alpha(0.8)       \n",
    "        child.set_color('#333333') \n",
    "for child in ax.get_children():\n",
    "    if isinstance(child, mpl.collections.PathCollection):\n",
    "        child.set_linewidths(1.5)  \n",
    "        child.set_sizes([40])      \n",
    "\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)        \n",
    "plt.tick_params(axis='both', width=2, length=6, labelsize=12)\n",
    "\n",
    "if len(fig.axes) > 1:\n",
    "    cb_ax = fig.axes[1]\n",
    "    cb_ax.tick_params(labelsize=14)\n",
    "    cb_ax.set_ylabel(\"Feature value\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct force plot call for a single instance\n",
    "shap.force_plot(expected_value, shap_values, shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "src_names = ['$T_{Re}$', '$T_{Se}$', '$c_{Re}$', '$f_{H_2}$','Sub.']\n",
    "i=25 # 1,25,88\n",
    "shap.plots.force(explainer.expected_value, shap_values[i,:], feature_names=src_names , \n",
    "                 link='identity', plot_cmap='RdBu', matplotlib=True, show=False, figsize=(16, 3), \n",
    "                 ordering_keys=None, ordering_keys_time_format=None, text_rotation=0, \n",
    "                 contribution_threshold=0.05)\n",
    "n=3\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "for line in ax.lines:\n",
    "    line.set_linewidth(n)\n",
    "\n",
    "ax.set_xlim(1.30, 1.60)\n",
    "\n",
    "plt.tick_params(axis='both',width=n,length=14)\n",
    "ax.spines['top'].set_linewidth(n)\n",
    "\n",
    "mpl.rcParams['font.size'] =25\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "# mpl.rcParams['mathtext.default'] = 'regular'\n",
    "mpl.rcParams['mathtext.default'] = 'it'\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
